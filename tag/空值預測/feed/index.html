<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>空值預測 &#8211; 果醬珍珍•JamJam</title>
	<atom:link href="/tag/%e7%a9%ba%e5%80%bc%e9%a0%90%e6%b8%ac/feed/" rel="self" type="application/rss+xml" />
	<link>/</link>
	<description>健忘女孩Jam的學習筆記和生活雜記</description>
	<lastBuildDate>Sun, 14 Apr 2019 15:00:57 +0000</lastBuildDate>
	<language>zh-TW</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.7.2</generator>
	<item>
		<title>Tree Surrogate &#124; Tree Surrogate Variables in CART &#124; R 統計</title>
		<link>/decision-tree-surrogate-in-cart/</link>
					<comments>/decision-tree-surrogate-in-cart/#respond</comments>
		
		<dc:creator><![CDATA[jamleecute]]></dc:creator>
		<pubDate>Sun, 02 Sep 2018 14:33:42 +0000</pubDate>
				<category><![CDATA[ 程式與統計]]></category>
		<category><![CDATA[統計模型]]></category>
		<category><![CDATA[tree surrogate]]></category>
		<category><![CDATA[樹替代]]></category>
		<category><![CDATA[決策樹空值填補]]></category>
		<category><![CDATA[空值填補]]></category>
		<category><![CDATA[空值預測]]></category>
		<guid isPermaLink="false">/?p=1039</guid>

					<description><![CDATA[<p>Tree Surrogate 樹替代是決策樹CART演算法裡面內建的處理遺失值的一個很棒的演算法。只要資料列有目標變數搭配只少一個未遺失的特徵值，即可進行遺失值 [&#8230;]</p>
<p>這篇文章 <a rel="nofollow" href="/decision-tree-surrogate-in-cart/">Tree Surrogate | Tree Surrogate Variables in CART | R 統計</a> 最早出現於 <a rel="nofollow" href="/">果醬珍珍•JamJam</a>。</p>
]]></description>
										<content:encoded><![CDATA[<p>Tree Surrogate 樹替代是決策樹CART演算法裡面內建的處理遺失值的一個很棒的演算法。只要資料列有目標變數搭配只少一個未遺失的特徵值，即可進行遺失值的預測，計算預測遺失值的surrogate variable list來作為替代值順位。</p>
<h3>CART決策樹模型遺失值預測法 Tree Surrogate 簡介</h3>
<ul>
<li>在使用rpart()(Recursive Partitioning Tree)建模時，我們不用特別針對遺失值進行處理。</li>
<li>只要觀測值有y值，和至少一個未遺失的x值，則可投入模型。</li>
<li>在遇到觀測資料有遺失值的情況，會使用Surrogate Variable List中的代理變數順位最高者來預測遺失變數值</li>
</ul>
<h3>Tree Surrogate Variables</h3>
<table>
<colgroup>
<col />
<col />
<col />
<col />
<col /></colgroup>
<tbody>
<tr bgcolor="#ddd">
<td class="">
<div>ID</div>
</td>
<td class="">
<div>A</div>
</td>
<td class="">
<div>B</div>
</td>
<td class="">
<div><span style="color: #0000ff;">C</span></div>
</td>
<td class="">
<div>T</div>
</td>
</tr>
<tr>
<td class="">
<div>1</div>
</td>
<td class="">
<div>T</div>
</td>
<td class="">
<div>?</div>
</td>
<td class="">
<div>F</div>
</td>
<td class="">
<div>Y</div>
</td>
</tr>
<tr>
<td class="">
<div>2</div>
</td>
<td class="">
<div>?</div>
</td>
<td class="">
<div>F</div>
</td>
<td class="">
<div>?</div>
</td>
<td class="">
<div>N</div>
</td>
</tr>
<tr>
<td class="">
<div>3</div>
</td>
<td class="">
<div>F</div>
</td>
<td class="">
<div>F</div>
</td>
<td class="">
<div>F</div>
</td>
<td class="">
<div>Y</div>
</td>
</tr>
<tr>
<td class="">
<div>4</div>
</td>
<td class="">
<div>F</div>
</td>
<td class="">
<div>T</div>
</td>
<td class="">
<div>T</div>
</td>
<td class="">
<div>N</div>
</td>
</tr>
</tbody>
</table>
<p>其中：</p>
<ul>
<li>T欄為目標變數</li>
<li>A,B,C欄為預測變數</li>
<li>而根據Gini Index，C會被選中為決策樹變數</li>
</ul>
<p>對於C欄位有遺失值的觀測資料列，CART決策樹會使用計算出來的代理變數(Surrogate Variables)來預測C值。</p>
<p>計算C欄位Surrogate Variables的方法如下：依據計算除了C以外的預測變數作為Surrogate Variables的錯誤率並比較排序。</p>
<p>Step 1: C is missing but B has value</p>
<div>首先計算B作為Surrogate Variable的錯誤率：</div>
<div></div>
<table>
<colgroup>
<col />
<col /></colgroup>
<tbody>
<tr bgcolor="#ddd">
<td class="">
<div>B</div>
</td>
<td class="">
<div>C</div>
</td>
</tr>
<tr>
<td class="">
<div>F</div>
</td>
<td class="">
<div>F</div>
</td>
</tr>
<tr>
<td class="">
<div>T</div>
</td>
<td class="">
<div>T</div>
</td>
</tr>
</tbody>
</table>
<div></div>
<div>使用決策樹模型產生用B預測C的邏輯：</div>
<ul>
<li>
<div>B=T -&gt; C=T</div>
</li>
<li>
<div>B=F -&gt; C=F</div>
</li>
<li>
<div>Error rate = 0%</div>
</li>
</ul>
<div>
<div>Step 2: C is missing but A has value</div>
</div>
<div>計算Ａ作為Surrogate Variable預測C值得錯誤率：</div>
<div></div>
<div>
<table>
<colgroup>
<col />
<col /></colgroup>
<tbody>
<tr bgcolor="#ddd">
<td class="">A</td>
<td class="">C</td>
</tr>
<tr>
<td class="">
<div>T</div>
</td>
<td class="">
<div>F</div>
</td>
</tr>
<tr>
<td class="">
<div>F</div>
</td>
<td class="">
<div>F</div>
</td>
</tr>
<tr>
<td class="">
<div>F</div>
</td>
<td class="">
<div>T</div>
</td>
</tr>
</tbody>
</table>
<p>使用決策樹模型產生用A預測C的邏輯：</p>
<ul>
<li>
<div>A=T -&gt; C=F</div>
</li>
<li>
<div>A=F -&gt; C=T</div>
</li>
<li>
<div>Erro rate = 33%</div>
</li>
</ul>
<div>
<div>總結以上，預測C欄位各Surrogate Variables的預測錯誤率分別為：</div>
</div>
<ul>
<li>
<div>A 有33% 的預測錯誤率</div>
</li>
<li>
<div>B 有0％的預測錯誤率</div>
</li>
<li>
<div>Naive隨機則有50%的預測錯誤率 (blind rule)</div>
</li>
<li>若錯誤率比Naive隨機預測結果還高者，會從Surrogate Variables list給移除</li>
</ul>
<div>因此，Surrogate Variables的順位為：B,A,Naive</div>
<ul>
<li>
<div>以ID2為例，C值會被指派為（根據B）F</div>
</li>
</ul>
<div align="center"><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><br />
<!-- text & display ads 1 --><br />
<ins class="adsbygoogle" style="display: block;" data-ad-client="ca-pub-7946632597933771" data-ad-slot="8154450369" data-ad-format="auto" data-full-width-responsive="true"></ins><br />
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script></div>
<p>更多rpart()函數對surrogate variable說明可參考：<a href="https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf" target="_blank" rel="noopener noreferrer">https://cran.r-project.org/web/packages/rpart/vignettes/longintro.pdf</a></p>
<hr />
<p>更多統計模型筆記連結：</p>
<p><a href="/linear_regression_using_airquality_dataset/" target="_blank" rel="noopener noreferrer">線性回歸模型</a></p>
<p><a href="/logistic_regression_part1/" target="_blank" rel="noopener noreferrer">羅吉斯回歸模型part1</a></p>
<p><a href="/logistic_regression_part2/" target="_blank" rel="noopener noreferrer">羅吉斯回歸模型part2</a></p>
<p style="text-align: left;"><a href="/decision_tree_cart/" target="_blank" rel="noopener noreferrer">決策樹/隨機森林</a></p>
<p><a href="/random-forests-%e9%9a%a8%e6%a9%9f%e6%a3%ae%e6%9e%97/" target="_blank" rel="noopener noreferrer">random forests</a></p>
<p><a href="/gradient-boosting-machines-gbm/" target="_blank" rel="noopener noreferrer">Gradient Boosting Machines (GBMs)</a></p>
<p><a href="/hierarchical-clustering/" target="_blank" rel="noopener noreferrer">階層式分群法</a></p>
<p><a href="/partitional-clustering-kmeans-kmedoid/" target="_blank" rel="noopener noreferrer">分割式分群法</a></p>
</div>
<p>這篇文章 <a rel="nofollow" href="/decision-tree-surrogate-in-cart/">Tree Surrogate | Tree Surrogate Variables in CART | R 統計</a> 最早出現於 <a rel="nofollow" href="/">果醬珍珍•JamJam</a>。</p>
]]></content:encoded>
					
					<wfw:commentRss>/decision-tree-surrogate-in-cart/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
	</channel>
</rss>
